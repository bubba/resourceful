\chapter{Properties}\label{cha:properties}
A type system is no good unless we can prove it is worth its salt. In
this section we will prove a number of lemmas and theorems which will
eventually show that the type system is sound. We will begin with a
couple of properties about contexts that we will later use on in
various other proofs. The first states that if we have two variables
in the context with the same names but different type schemes, then we
can ignore the first one as it is overshadowed by the second --- any
reference to $x$ will result in $x : \sigma'$.
\begin{lemma}[Drop]\label{lem:drop}
  If $\Gamma , x : \sigma, x : \sigma' \vdash e : \tau$, then $\Gamma , x : \sigma' \vdash e : \tau$
\end{lemma}
The second states that we can sneak in another variable before another
variable of the same name, for the exact same reason.
\begin{lemma}[Sneak]\label{lem:sneak}
  If $\Gamma , x : \sigma' \vdash e : \tau$, then for any $\sigma$, $\Gamma , x : \sigma, x : \sigma' \vdash e : \tau$
\end{lemma}
We can then also say that if two variables $x$ and $y$ are indeed
different, we are free to permute them and swap them about.
\begin{lemma}[Swap]\label{lem:swap}
  If $x \neq y$ and $\Gamma , x : \sigma, y : \sigma' \vdash e : \tau$, then $\Gamma , y : \sigma' , x : \sigma \vdash e
  : \tau$
\end{lemma}
And if we have a typing judgement in an empty context, we can weaken
the judgement to extend this to any other context.
\begin{lemma}[Weaken]\label{lem:weaken}
  If $\centerdot \vdash e : \tau$, then for $\Gamma$, $\Gamma \vdash e : \tau$.
\end{lemma}

We will also need to show this property about instantiation and the
close function.
\begin{lemma}\label{lem:close>}
  If $\sigma > \sigma'$ then $\overline{\Gamma , x : \sigma}(\tau) > \overline{\Gamma, x : \sigma'}(\tau)$.
\end{lemma}
\begin{proof}
  We provide an informal proof as follows.
  \begin{enumerate}
  \item If $\sigma > \sigma'$, then for every $\tau$ that $\sigma > \tau$, $\sigma' > \tau$.
  \item So $\sigma$ must parameterise over at least the same number of type
    variables if not \textit{more} than $\sigma'$.
  \item So $\sigma$ has at least the same number of free type variables if
    not \textit{less} than $\sigma'$.
  \item By definition of the close function,
    $\overline{\Gamma, x : \sigma}(\tau)$ will then have at least the same number
    of bound type variables if not \textit{more} than
    $\overline{\Gamma, x : \sigma'}(\tau)$.
  \item So if $\overline{\Gamma, x : \sigma'}(\tau)$ can be instantiated to some
    $\tau$, then $\overline{\Gamma, x : \sigma}(\tau)$ can also be instantiated to
    that $\tau$, as it has enough bound type variables to handle
    everything the former can --- if it had less type variables than the
    former, then it would not be able to instantiate these types, but
    for the converse excess type variables can be mapped to whatever.
  \end{enumerate}
\end{proof}

Now we prove the generalisation theorem, which states that if a type
scheme inside the context is an instantiation of another type scheme,
then we can use the more general type scheme and preserve how things
are typed. This is an adaptation of a lemma from Wright and
Felleisen~\cite[Lemma 4.6]{wright1994}, which is in turn an
adaptation of a lemma from Damas and Milner.

\begin{theorem}[Generalisation]\label{lem:generalisation}
  If $\Gamma, x : \sigma' \vdash e : \tau$ and $\sigma > \sigma'$, then \\ ${\Gamma, x : \sigma \vdash e : \tau}$.
\end{theorem}
\begin{proof}
  Begin with induction on the proof for $\Gamma , x : \sigma' \vdash e : \tau$.
  \begin{description}
  \item[\rm\textsc{Var}]
    From the premises we have $x : \sigma' \in \Gamma$ and $\sigma' > \tau$. We also have
    $\sigma > \sigma'$ but by definition of $\sigma > \sigma'$, if $\sigma' > \tau$ then $\sigma > \tau$.
    And we also have by definition $x : \sigma \in \Gamma , x : \sigma$. So putting the
    pieces together, we can use \textsc{Var} to get
    \begin{mathpar}
      \infer{x : \sigma \in \Gamma , x : \sigma \\ \sigma > \tau}
      {\Gamma , x : \sigma \vdash x : \tau}
    \end{mathpar}
  \item[\rm\textsc{Abs}]
    We have $\Gamma , x : \sigma' \vdash \lambda y . e : \tau$. If $x = y$, then we can safely
    say the premise $\Gamma , x : \sigma' , y : \sigma'' \vdash e : \tau$ becomes $\Gamma , y :
    \sigma'' \vdash e : \tau$  due to Lemma~\ref{lem:drop}. And from this we can
    then use Lemma~\ref{lem:sneak} to get $\Gamma, x : \sigma, y : \sigma'' \vdash e : \tau$,
    and ultimately $\Gamma , x : \sigma \vdash \lambda y . e : \tau$.

    If $x \neq y$, then we can get $\Gamma , y : \sigma'' , x : \sigma' \vdash e : \tau$ via
    Lemma~\ref{lem:swap}. The induction hypothesis then results in $\Gamma
    , y : \sigma'' , x : \sigma \vdash e : \tau$, which we can then swap back again to
    get $\Gamma , x : \sigma , y : \sigma'' \vdash e : \tau$ and so $\Gamma , x : \sigma \vdash \lambda y . e :
    \tau$.
  \item[\rm\textsc{Let}]
    For $\letin{y = e'}{e}$, we have $\Gamma , x : \sigma' \vdash e' : \tau'$ and $\Gamma , x :
    \sigma' , y : \overline{\Gamma , x : \sigma'}(\tau') \vdash e : \tau$, and we aim to show
    $\Gamma , x : \sigma \vdash \letin{y=e'}{e} : \tau$.
    
    First off, we need to convert the $y : \overline{\Gamma , x : \sigma'}(\tau')$ to a
    $y : \overline{\Gamma, x : \sigma}(\tau')$ somehow. But it can be shown that if $\sigma >
    \sigma'$, then $\overline{\Gamma , x : \sigma}(\tau) > \overline{\Gamma , x : \sigma'}(\tau)$ due
    to Lemma~\ref{lem:close>}. So by the inductive hypothesis,
    we are able to get $\Gamma , x : \sigma' , y : \overline{\Gamma, x : \sigma}(\tau') \vdash e : \tau$.

    If $x = y$ then we can drop $x :
    \sigma'$ from the context and sneak it back in as $\Gamma , x : \sigma, y :
    \overline{\Gamma, x : \sigma}(\tau') \vdash e : \tau$ with Lemma~\ref{lem:drop} and
    Lemma~\ref{lem:sneak}. The induction hypothesis then gives us $\Gamma ,
    x : \sigma \vdash e' : \tau'$ and we construct the proof back together with
    \textsc{Let} to give $\Gamma , x : \sigma \vdash \letin{y = e'}{e} : \tau$.

    If $x \neq y$, then the proof is a bit more complicated. We take the
    following steps:
    \begin{align*}
      \Gamma , x : \sigma' , y : \overline{\Gamma, x : \sigma}(\tau') \vdash e : \tau \\
      \Gamma , y : \overline{\Gamma, x : \sigma}(\tau') , x : \sigma' \vdash e : \tau &&  \text{by
                                                            swapping,
                                                            Lemma~\ref{lem:swap}}
      \\
      \Gamma , y : \overline{\Gamma, x : \sigma}(\tau') , x : \sigma \vdash e : \tau && \text{by
                                                           inductive
                                                           hypothesis} \\
      \Gamma , x : \sigma , y : \overline{\Gamma, x : \sigma}(\tau') \vdash e : \tau && \text{by swapping again}
    \end{align*}
    And proceed to construct the proof for \textsc{Let} as previously.
  \item[\rm\textsc{App}]
    From the premises we have $\Gamma , x : \sigma' \vdash e : \tau' \rightarrow \tau$ and $\Gamma , x : \sigma' \vdash
    e' : \tau'$. We wish to show $\Gamma , x : \sigma \vdash e \ e' : \tau$.
    We apply the induction hypothesis to get $\Gamma , x : \sigma \vdash e : \tau' \rightarrow \tau$
    and  $\Gamma , x : \sigma \vdash e' : \tau$. Then use \textsc{App} to build up a
    proof of $\Gamma , x : \sigma \vdash e \ e' : \tau$.
  \item[The remaining cases] The rest of the possible proofs for
    $\Gamma , x : \sigma' \vdash e : \tau$ can all be proved by applying the
    induction hypothesis on their structure, much like the case for
    \textsc{App}, and so are omitted for brevity.
  \end{description}
\end{proof}

If a context has all the same type schemes for each free variable in
an expression as another context, then we can make the same typing
judgements with that context. In other words, we are free to ignore
extra variables not used by the expression.
\begin{lemma}\label{lem:ignore}
  If for all $x \in \fv(e)$ where $x : \sigma \in \Gamma$, $x : \sigma \in \Delta$, and if $\Gamma \vdash
  e : \tau$ then $\Delta \vdash e : \tau$.
\end{lemma}

We can also show that we can apply a substitution to both the context
and type given in a judgement.
\begin{lemma}\label{lem:subContextTyping}
  If $\Gamma \vdash e : \tau$, then for any substitution $s$, $\Gamma[s] \vdash e : \tau[s]$.
\end{lemma}

An important lemma that we need to show is the substitution
lemma, which relates to substituting a variable for an expression,
whose type we can prove. The following proof is adapted from Wright
and Felleisen~\cite{wright1994}.

\begin{lemma}[Substitution]\label{lem:substitution}
  If $\Gamma \vdash e : \tau$ and ${\Gamma , x : \forall \alpha_1, \ldots, \alpha_n . \tau \vdash e' : \tau'}$, and ${x \notin \dom(\Gamma)}$ and
  ${\alpha_1 , \ldots, \alpha_n \cap \ftv(\Gamma) = \emptyset}$, then ${\Gamma \vdash e' [e/x] : \tau'}$.
\end{lemma}
Note that the domain of a context $\dom(\centerdot , x_1 : \sigma_1 , \ldots , x_n :
\sigma_n)$ is defined as $\{ x_1 , \ldots , x_n \}$.
\begin{proof}
  Begin with induction on the proof of $\Gamma , x : \forall \alpha_1 \ldots \alpha_n . \tau \vdash e'
  : \tau'$. For brevity we will sometimes refer to $\forall \alpha_1,\ldots,\alpha_n . \tau$ as $\sigma$.
  \begin{description}
  \item[\rm\textsc{Var}] We have
    $\Gamma , x : \forall\alpha_1\ldots\alpha_n \vdash y : \tau'$ and want to show $\Gamma \vdash y[e/x] : \tau'$.

    If $y \neq x$, then by definition $y [e/x] = y$, so we just need to
    show $\Gamma \vdash y : \tau'$. From the premises we also have
    $y : \tau' \in \Gamma , x : \forall\alpha_1\ldots\alpha_n$, but since $y \ne x$ we have $y : \tau' \in \Gamma$. And
    from here we can use \textsc{Var} to get $\Gamma \vdash y : \tau'$.

    If $y = x$, then we need to show $\Gamma \vdash x : \tau'$. From the premise of
    ${\Gamma , x : \forall \alpha_1\ldots\alpha_n . \tau \vdash x : \tau'}$ we have
    ${\forall \alpha_1\ldots\alpha_n . \tau > \tau'}$, so there exists a substitution
    $s$ which replaces exactly $\alpha_1,\ldots,\alpha_n$, such that
    $\tau[s] = \tau'$.

    We can use Lemma~\ref{lem:subContextTyping} to get
    $\Gamma[s] \vdash e : \tau[s]$, or $\Gamma[s] \vdash e : \tau'$. And furthermore, because
    ${\alpha_1 , \ldots, \alpha_n \cap \ftv(\Gamma) = \emptyset}$, applying $s$ to $\Gamma$ will do
    nothing since $\Gamma$'s free type variables are distinct, i.e. $\Gamma =
    \Gamma[s]$. Leaving us with $\Gamma \vdash e : \tau'$ as required.

  \item[\rm\textsc{Abs}]
    We have $\Gamma , x : \forall\alpha_1\ldots\alpha_n \vdash \lambda y . e' : \tau_1 \rightarrow \tau_2$ and want to show
    \[\Gamma \vdash (\lambda y . e')[e/x] : \tau_1 \rightarrow \tau_2\]
    Similarly to the case for $\textsc{var}$, we first check to see if
    $x = y$. If $y = x$, then the inner binding of $y$ will shadow $x$. That
    is, we have the premise $\Gamma , x : \sigma, x : \tau_1 \vdash e' : \tau_2$, and we can
    drop the previous $x$ from the context with
    Lemma~\ref{lem:drop} to get $\Gamma , x : \tau_1 \vdash e' : \tau_2$.
    By definition, if $x = y$ then $(\lambda y . e')[e/x] = \lambda y . e'$, so we
    just need to show $\Gamma \vdash \lambda y . e' : \tau_1 \rightarrow \tau_2$, which can construct
    with \textsc{Abs} and $\Gamma , x : \tau_1 \vdash e' : \tau_2$.

    If $y \ne x$, then the proof is more involved. From the premises
    we have
    \[\Gamma , x : \forall \alpha_1\ldots\alpha_n . \tau , y : \tau_1 \vdash e' : \tau_2\]
    We start by choosing a substitution $s$, which maps $\alpha_1 , \ldots, \alpha_n$
    to fresh type variables $\alpha'_1, \ldots,\alpha'_n$. Additionally, they are
    distinct as follows.
    \[\ftv(\Gamma) \cap \alpha_1,\ldots,\alpha_n \cap \alpha'_1,\ldots,\alpha'_n = \emptyset\]

    Now we manipulate the premise in the following order.
    \begin{align*}
      \Gamma , y : \tau_1 , x : \forall\alpha_1\ldots\alpha_n . \tau &\vdash e' : \tau_2 && \text{by swapping,
                                                   Lemma~\ref{lem:swap}}
      \\
      (\Gamma , y : \tau_1 , x : \forall\alpha_1\ldots\alpha_n . \tau)[s] &\vdash e' : \tau_2 && \text{by
                                                     Lemma~\ref{lem:subContextTyping}}
      \\
      \Gamma , y : \tau_1[s] , x : (\forall\alpha_1\ldots\alpha_n . \tau)[s] &\vdash e' : \tau_2 &&
                                                            \text{since
                                                            } \Gamma[s] = \Gamma
    \end{align*}
    And since the range of $s$ is exactly $\alpha_1,\ldots,\alpha_n$, we have
    $(\forall \alpha_1\ldots\alpha_n . \tau)[s] = \forall \alpha_1\ldots\alpha_n . \tau$ --- substitution only
    substitutes free type variables, not bound type variables, and
    here any possible free type variables are being shadowed.
    \begin{equation}
      \Gamma , y : \tau_1[s] , x : \forall \alpha_1\ldots\alpha_n . \tau \vdash e' : \tau_2
      \label{eq:substAbs2}
    \end{equation}

    % $\Gamma(z) = (\Gamma , y : \tau_1[s])(z)$ for all $z \in \fv(e)$
    We can apply Lemma~\ref{lem:ignore} to $\Gamma \vdash e : \tau$, giving us
    \begin{equation}
      \Gamma , y : \tau_1[s] \vdash e : \tau\label{eq:substAbs3}
    \end{equation}
    And when we combine $x \notin \dom(\Gamma)$ with the fact that $x \ne y$, we get
    \begin{equation}
      x \notin \dom(\Gamma , y : \tau_1[s])
      \label{eq:substAbsNotIn}
    \end{equation}
    Because of how we chose $s$, we also have
    \begin{equation}
      \ftv(\Gamma, y : \tau_1[s]) \cap {\alpha_1,\ldots,\alpha_n} = \emptyset\label{eq:substAbs4}
    \end{equation}
    Eventually, we use (\ref{eq:substAbs3}), (\ref{eq:substAbs2}),
    (\ref{eq:substAbsNotIn}) and (\ref{eq:substAbs4}) with the
    induction hypothesis to arrive at
    \[ \Gamma , y : \tau_1[s] \vdash e' [e/x] : \tau_2[s] \]
    But $s$ is a bijection due to how we chose it: That means an
    inverse, $s^{-1}$ exists. We ``apply it to both sides'' with
    Lemma~\ref{lem:subContextTyping}
    \begin{align*}
      (\Gamma , y : \tau_1[s])[s^{-1}] &\vdash e' [e/x] : (\tau_2[s])[s^{-1}] \\
      (\Gamma , y : \tau_1[s])[s^{-1}] &\vdash e' [e/x] : \tau_2 \\
      \Gamma[s^{-1}] , y : \tau_1[s][s^{-1}] &\vdash e' [e/x] : \tau_2 \\
      \Gamma[s^{-1}], y : \tau_1 &\vdash e' [e/x] : \tau_2
    \end{align*}
    And because $\alpha'_1 , \ldots, \alpha'_n \cap \ftv(\Gamma) = \emptyset$, we can get rid of that
    last substitution and arrive at ${\Gamma, y : \tau_1 \vdash e' [e/x] : \tau_2}$.
    From here, we build our way back up with \textsc{Abs}.
    \begin{align*}
      \Gamma \vdash \lambda y . (e' [e/x]) : \tau_1 \rightarrow \tau_2 \\
      \Gamma \vdash (\lambda y . e')[e/x] : \tau_1 \rightarrow \tau_2 && \text{because } x \ne y
    \end{align*}
    
  \item{\rm\textsc{Let}} We have the proof ${\Gamma , x : \sigma \vdash \letin{y = e_1}{e_2} :
      \tau'}$
    and want to show
    \[\Gamma \vdash (\letin{y = e_1}{e_2})[e/x] : \tau'\]
    The first premise can be fed directly into the induction hypothesis
    \begin{align}
      \Gamma , x : \forall \alpha_1\ldots\alpha_n . \tau \vdash e_1 : \tau_1 \nonumber \\
      \Gamma \vdash e_1 [e / x] : \tau_1 \label{eq:substLet7}
    \end{align}

    Now if $x = y$, we take the second premise as follows
    \begin{align*}
      \Gamma , x : \forall \alpha_1\ldots\alpha_n . \tau , x : \overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n . \tau}(\tau_1)
      \vdash e_2 : \tau' \\
      \Gamma , x : \overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n . \tau}(\tau_1) \vdash e_2 : \tau' &&
                                                                \text{by
                                                                Lemma~\ref{lem:drop}}
      \\
      \Gamma \vdash \letin{x = e_1[e / x]}{e_2} : \tau' && \text{by \textsc{Let}}
    \end{align*}
    Since $x = y$, by the definition of substitution
    $\letin{y=e_1[e/x]}{e_2}$ is equivalent to $(\letin{y=e_1}{e_2})[e/x]$.
    And so we reach our goal
    \[\Gamma \vdash (\letin{y = e_1}{e_2})[e/x] : \tau'\]

  If we are unfortunate enough that $y \ne x$, then from the second
  premise we use the swap lemma to get
  \begin{equation}\label{eq:substLet8}
    \Gamma , y : \overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n . \tau}(\tau_1), x : \forall \alpha_1\ldots\alpha_n . \tau  \vdash
    e_2 : \tau'
  \end{equation}
  And since we have $\Gamma \vdash e : \tau$, from Lemma~\ref{lem:ignore}
  there is
  \begin{equation}\label{eq:substLet9}
  \Gamma , y : \overline{\Gamma , x :\forall\alpha_1\ldots\alpha_n . \tau}(\tau_1) \vdash e : \tau    
  \end{equation}
  Now we want to call the inductive hypothesis on (\ref{eq:substLet8})
  and (\ref{eq:substLet9}), but that means we first need to show
  \[\{ \alpha_1,\ldots,\alpha_n\} \cap \ftv(\Gamma , y : \overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n . \tau}(\tau_1))
    = \emptyset\]
  We do this as follows:
  \begin{align*}
    & \{ \alpha_1,\ldots,\alpha_n\} \cap \ftv(\Gamma , y : \overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n . \tau}(\tau_1)) \\
    &\subseteq \{ \alpha_1,\ldots,\alpha_n\} \cap (\ftv(\Gamma) \cup \ftv(\overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n
      . \tau}(\tau_1))) \\
    &= \{ \alpha_1,\ldots,\alpha_n\} \cap (\ftv(\overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n . \tau}(\tau_1)))
    \\
    &= \{ \alpha_1,\ldots,\alpha_n\} \cap (\ftv(\tau_1) \setminus (\ftv(\tau_1) \setminus \ftv(\Gamma,x:\forall
      \alpha_1\ldots\alpha_n.\tau))) \\
    &= \{ \alpha_1,\ldots,\alpha_n\} \cap \ftv(\tau_1) \cap \ftv(\Gamma, x : \forall \alpha_1\ldots\alpha_n . \tau) \\
    &\subseteq \{ \alpha_1,\ldots,\alpha_n\} \cap \ftv(\Gamma, x : \forall \alpha_1\ldots\alpha_n . \tau) \\
    &= \{ \alpha_1,\ldots,\alpha_n\} \cap (\ftv(\Gamma) \cup \ftv(\forall \alpha_1\ldots\alpha_n . \tau)) \\
    &= \{ \alpha_1,\ldots,\alpha_n\} \cap \ftv(\forall \alpha_1\ldots\alpha_n . \tau) \\
    &= \{ \alpha_1,\ldots,\alpha_n\} \cap \ftv(\tau) \setminus \{\alpha_1,\ldots,\alpha_n\} \\
    &= \emptyset
  \end{align*}
  And then we can use it to arrive at
  \[ \Gamma , y : \overline{\Gamma, x : \forall\alpha_1\ldots\alpha_n.\tau}(\tau_1) \vdash e_2 [e/x] : \tau' \]
  The next part involves an observation, that for any $x$, $\tau$ and $\sigma$ in
  any $\Gamma$, ${\overline{\Gamma}(\tau) > \overline{\Gamma, x : \sigma}(\tau)}$, as closing
  over a context with a \textit{smaller} domain will result in the
  type scheme having \textit{more} bound type variables --- i.e.\ it is
  more general. Therefore we can use the generalisation lemma,
  Lemma~\ref{lem:generalisation}, to get
  \begin{align*}
    \Gamma , y : \overline{\Gamma}(\tau_1) \vdash e_2[e/x] : \tau' \\
    \Gamma \vdash \letin{y = e_1[e/x]}{e_2[e/x]} : \tau' && \text{with \textsc{Let}
                                               and
                                               (\ref{eq:substLet7})}
    \\
    \Gamma \vdash (\letin{y = e_1}{e_2})[e/x] : \tau' && \text{by definition of substitution}
  \end{align*}
  
  \item[The remaining cases] The rest of the proofs for $\Gamma \vdash e'[e/x] :
    \tau'$ are proved by applying the induction hypothesis on their structure.
  \end{description}
\end{proof}

\section{Type Soundness}

Now that we have the prerequisite lemmas out of the way, we can move
onto proving that the system is \textbf{sound}. Soundness is a
property of a logical system, stating that every judgement that can be
proved within the system is valid. In the type theory realm, a type
system is considered to be sound if and only if, for every typing
judgement we can produce for an expression in a context, it evaluates
to some member of the set of the type from the typing judgement --- or
as Milner put it, \textit{``well-typed programs can't go
  wrong''}~\cite{milner1978}[ยง3.7].
\[\Gamma \vdash e : \tau \rightarrow \Gamma \Vdash e : \tau\]
We saw how this was proved with denotational semantics in
Chapter~\ref{chapter:background}, but here we have modelled our
dynamic semantics with operational semantics.  Instead, we prove the
soundness of our type system \textit{syntactically}. This approach was
first introduced by Wright and Felleisen and 1994~\cite{wright1994},
and has since become the de facto method for proving soundness
with operational semantics.

Syntactic type soundness involves proving two properties of a type
system, \textit{type progress} and \textit{type preservation}.
The former states that for any typing judgement we can prove, the
expression is either a terminal value, or can be reduced further. The
latter property ensures that when an expression has a type, reducing
it to another expression does not change the type.
The proofs of both of these properties come from induction on the
proof of the typing judgement:

\begin{theorem}[Progress]\label{thm:progress}
  If $\centerdot \vdash e : \tau$, then either $\textsf{value} \ e$ or there exists a $e'$ such that $e \leadsto e'$.
\end{theorem}
\begin{proof}
  Begin by induction on $\centerdot \vdash e : \tau$.
  \begin{description}
  \item[\rm\textsc{Var}] This case is not possible --- it is impossible
    to construct a proof for $x \in \centerdot$, and thus impossible to arrive at
    $\centerdot \vdash x : \tau$.
  \item[\rm\textsc{Abs}] Any lambda abstraction is a value due to the
    rule
    \[\infer{ }{\textsf{Value} \ \lambda x . e}\]
  \item[\rm\textsc{App}] We have $\centerdot \vdash e_1 \ e_2 : \tau$, so by the premises
    of \textsc{App}, we have $\centerdot \vdash e_1 : \tau' \rightarrow \tau$ and $\centerdot \vdash e_2 :
    \tau'$.

    Consider the induction hypothesis on the first premise. Either
    $\textsf{value} \ e_1$, or $e_1 \leadsto e_1'$. In the latter case where
    $e_1$ reduces, we can then construct a proof that $e_1 \ e_2$
    reduces, and we're done.
    \[\infer{e_1 \leadsto e_1'}{e_1 \ e_2 \leadsto e_1' \ e_2}\]
    In the former case where $e_1$ is a value, we then apply the
    induction hypothesis to $\centerdot \vdash e_2 : \tau'$. Again, if $e_2$ reduces
    further then we can also construct a proof that $e_1 \ e_2$
    reduces.
    
    But if $\textsf{value} \ e_2$, we cannot reduce in the same way
    again. Instead, since we know $e_1$ is a value, and since we also
    know that $\centerdot \vdash e_1 : \tau' \rightarrow \tau$, we can deduce that
    $e_1$ must be an abstraction: it has the form $\lambda x
    . e$. Furthermore, because $e_2$ is a value, we can then apply the
    beta reduction rule.
    \[\infer{\textsf{value} \ e_2}{(\lambda x . e) \ e_2 \leadsto e[e_2/x]}\]
    We are ``calling a function'' in this sense, and now have proof
    that it reduces.
  \item[\rm\textsc{Let}] Our dynamic semantics for \textsc{Let} are
    lazy: ${\letin{x = e'}{e}}$ can reduce without evaluating $e'$
    first. And so for every let statement, we can immediately reduce.
    \[\infer{ }{\letin{x = e'}{e} \leadsto e[e'/x]}\]
  \item[\rm\textsc{Unit}] All unit expressions are values.
    \[\infer{ }{\textsf{value} \ \square}\]
  \item[\rm\textsc{Product}] For $\centerdot \vdash e_1 \times e_2 : \tau_1 \times \tau_2$, we have
    the premises $\centerdot \vdash e_1 : \tau_1$ and $\centerdot \vdash e_2 : \tau_2$. Using the
    induction hypothesis on either, if either of them reduce further,
    then we can also reduce $e_1 \times e_2$.
    \begin{align*}
      \infer{e_1 \leadsto e_1'}{e_1 \times e_2 \leadsto e_1' \times e_2} &&
      \infer{e_2 \leadsto e_2'}{e_1 \times e_2 \leadsto e_1 \times e_2'}
    \end{align*}
    If both of them are values, then the product itself is a value.
    \[\infer{\textsf{value} \ e_1 \\ \textsf{value} \ e_2}{
        \textsf{value} \ e_1 \times e_2}\]
  \item[\rm\textsc{Proj1}] For $\centerdot \vdash \pi_1 \ e : \tau$, we have the premise
    $\centerdot \vdash e : \tau \times \tau'$. Applying the induction hypothesis to the
    premise, if it reduces further, then we can reduce the expression
    as well.
    \[\infer{e \leadsto e'}{\pi_1 \ e \leadsto \pi_1 \ e'}\]
    However, if $e$ is a value then we know it must be of the form
    $e_1 \times e_2$, as that is the only expression that can have a
    product type and be a value. Thus we can use the reduction rule
    \[\infer{ }{\pi_1 \ (e_1 \times e_2) \leadsto e_1}\]
  \item[\rm\textsc{Proj2}] The proof for \textsc{Proj2} is pretty much
    identical to that of \textsc{Proj1}, so we will omit it for
    brevity.
  \item[\rm\textsc{Lift}] All lifted expressions are also values by
    definition.
    \[\infer{ }{\textsf{value} \ \lift{e}}\]
  \item[\rm\textsc{Use}] And likewise, all use expressions are values
    by definition.
    \[\infer{ }{\textsf{value} \ \use{r}{e}}\]
  \item[\rm\textsc{Bind}] For $\centerdot \vdash e_1 \bind e_2 : \tau$, we have two
    premises, $\centerdot \vdash e_1 : \IO_\rho \tau'$ and
    $\centerdot \vdash e_2 : \tau' \rightarrow \IO_\rho \tau$. Applying the induction hypothesis to the
    first premise, if $e_1$ reduces further then we can also say
    $e_1 \bind e_2$ reduces further
    \[\infer{e_1 \leadsto e_1'}{e_1 \bind e_2 \leadsto e_1' \bind e_2} \]
    If $e_1$ turns out to be a value, then because it has the type
    $\IO_\rho \tau'$, it must be either of the form $\lift{e}$ or
    $\use{r}{e}$. These are the only expressions that can both be
    values and have the type $\IO_\rho \tau'$.
    In either case, there exist reduction rules for both of these.
    \begin{align*}
      \infer{ }{\lift{e} \bind e_2 \leadsto e_2 \ e}&&
      \infer{ }{\use{r}{e} \bind e_2 \leadsto e_2 \ e}
    \end{align*}
  \item[\rm\textsc{Conc}] We can immediately reduce any expression
    of the form $v \curlyvee w$.
    \[ \infer{ }{v \curlyvee w \leadsto v \bind \lambda v . (w \bind \lambda w . \lift{v \times
          w})} \]
  \item[\rm\textsc{Sub}] If we have a subsumption judgement resulting
      in $\centerdot \vdash e : \IO_\rho' \tau$, then we also have the premise $\centerdot \vdash e :
      \IO_\rho \tau$ for some other $\rho$. But we can just call the induction
      hypothesis on this premise to show that either $e$ reduces or
      $e$ is a value. In any case, it is the same $e$ --- so we are done.
  \end{description}
\end{proof}

\begin{theorem}[Preservation]\label{thm:preservation}
  If $\centerdot \vdash e : \tau$ and $e \leadsto e'$, then $\centerdot \vdash e' : \tau$.
\end{theorem}
\begin{proof}
  As usual, start with induction on the proof for $\centerdot \vdash e : \tau$.
  \begin{description}
  \item[\rm\textsc{Var}] Like with the proof for progress, it is not
    possible to have a typing judgement for a variable in the empty
    context.
  \item[\rm\textsc{Abs}] Whilst it is possible to have a typing
    judgement of $\centerdot \vdash \lambda x . e$, it is not possible to have a reduction
    of the form $(\lambda x . e) \leadsto e'$. A lambda abstraction cannot reduce
    any further, and so we do not need to consider this case.
  \item[\rm\textsc{App}] We have $\centerdot \vdash e_1 \ e_2 : \tau$. Consider the
    possible cases for $e_1 \ e_2 \leadsto e'$. When it is $e_1$ that has
    reduced
    \[ \infer{e_1 \leadsto e_1'}{e_1 \ e_2 \leadsto e_1' \leadsto e_2} \] We can use the
    induction hypothesis with this alongside the first premise
    ${\centerdot \vdash e_1 : \tau' \rightarrow \tau}$ to get
    \[ \centerdot \vdash e_1' : \tau' \rightarrow \tau \] And then using \textsc{App} and the second
    premise, we build up a proof for
    \[ \centerdot \vdash e_1' \ e_2 : \tau \]
    When it is $e_2$ that is reduced to $e_2'$, the steps are the same: Use the
    induction hypothesis to get $\centerdot \vdash e_2 : \tau'$, and then $\centerdot \vdash e_1 \
    e_2' : \tau$.
    However, there is one other scenario in which an application
    reduce, and that is through beta reduction:
    \[ \infer{\textsf{value} \ e_2}{ (\lambda x . e) \ e_2 \leadsto e [ e_2 / x ]
      } \]
    We need to
    show that $\centerdot \vdash e [ e_2 / x ] : \tau$.
    And in this case $e_1$ must be a lambda abstraction, so the
    typing judgement for the first premise must be a \textsc{Abs}.
    \[
      \infer*[Left=App]{ \infer*[Left=Abs]{\centerdot , x : \tau' \vdash e : \tau}{\centerdot \vdash \lambda x . e : \tau' \rightarrow \tau} \\ \centerdot \vdash e_2 : \tau' }
      {\centerdot \vdash (\lambda x . e) \ e_2  : \tau}
    \]
    Furthermore, we know that $\dom(\centerdot)$ and the bound type variables
    in $\tau'$ are distinct --- the domain of $\centerdot$ is empty, and there are
    no bound type variables in the type scheme $\tau'$.  This allows us
    to use the substitution lemma, Lemma~\ref{lem:substitution}, with $\centerdot \vdash e_2 : \tau'$ and
    $\centerdot , x : \tau' \vdash e : \tau$, giving us
    \[ \centerdot \vdash e [ e_2 / x ] : \tau \]
  \item[\rm\textsc{Let}] There is only way a let expression can
    reduce, and that is by
    \[\letin{x = e'}{e} \leadsto e [e' / x]\]
    The premises are
    \begin{align*}
      \centerdot \vdash e' : \tau' \\
      \centerdot , x : \tau' \vdash e : \tau
    \end{align*}
    And we know that there are no bound type variables in the type
    scheme $\tau'$, and so they are naturally distinct form
    $\dom(\centerdot)$. Therefore we can just use the substitution lemma again
    to show that
    \[ \centerdot \vdash e [e' / x] : \tau \]
  \item[\rm\textsc{Unit}] In this case, the judgement is
    $\centerdot : \square \vdash \square$. But there is no way for a unit
    $\square$ to reduce, i.e. $\square \not\leadsto e$, so we do not need to consider this case.
  \item[\rm\textsc{Product}] An expression of the form
    $\centerdot \vdash e_1 \times e_2: \tau_1 \times \tau_2$ can be reduced in either two
    ways. Either $e_1 \leadsto e_1'$ and
    $e_1 \times e_2 \leadsto e_1' \times e_2$, in which case
    \begin{align*}
      \centerdot \vdash e_1 : \tau_1 && \text{by the premises} \\
      \centerdot \vdash e_1' : \tau_1 && \text{by induction hypothesis} \\
      \centerdot \vdash e_1' \times e_2 : \tau_1 \times \tau_2 && \text{by \textsc{Product}}
    \end{align*}
    Or if $e_2 \leadsto e_2'$, then we repeat the same steps but acting on
    the second premise.
  \item[\rm\textsc{Proj1}] $\centerdot \vdash \pi_1 \ e : \tau$ can reduce in two ways as
    well. If $e \leadsto e'$ and $\pi_1 \ e \leadsto \pi_1 \ e'$ then
    \begin{align*}
      \centerdot \vdash e : \tau \times \tau' && \text{by the premises} \\
      \centerdot \vdash e' : \tau \times \tau' && \text{by induction hypothesis} \\
      \centerdot \vdash \pi_1 \ e' : \tau && \text{by \textsc{Proj1}}
    \end{align*}
    However it can also be reduced if $e$ happens to be a product,
    namely $\pi_1 (e_1 \times e_2) \leadsto e_1$. So we just need to show that
    ${\centerdot \vdash e_1 : \tau}$, which can be done by climbing up the proof tree.
    \[
      \infer*[Left=Proj1]{ \infer*[Left=Product]{\centerdot \vdash e_1 : \tau  \\ \centerdot \vdash
          e_2 : \tau}{\centerdot \vdash e_1
          \times e_2 : \tau \times \tau'} }
      {\centerdot \vdash \pi_1 \ (e_1 \times e_2) : \tau}
    \]
  \item[\rm\textsc{Proj2}] Again, the proof for \textsc{Proj2} is
    pretty much identical to that of \textsc{Proj1} and so is omitted
    for brevity.
  \item[\rm\textsc{Lift}] For
    $\centerdot \vdash \lift{e} : \IO_\rho \tau$, just like $\square$ there is no way
    for $\lift{e}$ to reduce any further --- they are both
    values. There is nothing needed to be done for this case.
  \item[\rm\textsc{Use}] The same also applies for $\use{r}{e}$.
  \item[\rm\textsc{Bind}] The proof we are handling looks like this
    \[ \infer*[Left=Bind]{\centerdot \vdash e_1 : \IO_\rho \tau' \\ \centerdot \vdash e_2 : \tau' \rightarrow \IO_\rho \tau}{\centerdot \vdash e_1 \bind
        e_2 : \IO_\rho \tau} \]
    The first thing to note is that there are
    multiple possible ways in which reduction could have occurred: We
    will look at each of them one by one.
    \begin{description}
    \item[$e_1 \bind e_2 \leadsto e_1' \bind e_2$] The premise for this
      reduction is $e_1 \leadsto e_1'$, so we take the following steps
      \begin{align*}
        \centerdot \vdash e_1 : \IO_\rho \tau' && \text{by the premises} \\
        \centerdot \vdash e_1' : \IO_\rho \tau' && \text{by induction hypothesis} \\
        \centerdot \vdash e_1' \bind e_2 : \IO_\rho \tau && \text{by \textsc{Bind}}
      \end{align*}
    \item[$\lift{e} \bind e_2 \leadsto e_2 \ e$] We know
      $\centerdot \vdash \lift{e} : \IO_\rho \tau'$, but that does not necessarily mean
      that the proof for it came from the \textsc{Lift} rule --- it
      could have also been derived from subsumption, \textsc{Sub}. To
      help when this scenario arises, we use a small helper lemma
      listed in the appendix, Lemma~\ref{lem:unwrapLift}, that says if
      $\Gamma \vdash \lift{e} : \IO_\rho \tau'$, then
      $\Gamma \vdash e : \tau'$. Now we can use \textsc{Abs} to construct
      ${\centerdot \vdash e_2 \ e : \IO_\rho \tau}$ as needed.
    \item[$\use{r}{e} \bind e_2 \leadsto e_2 \ e$] This is identical to the
      case above, except we use Lemma~\ref{lem:unwrapUse} instead.
    \end{description}
  \item[\rm\textsc{Conc}] We have the proof and premises
    \[ \infer*[Left=Conc]{\centerdot \vdash v : \IO_{\rho_1} \tau_1 \\ \centerdot \vdash w : \IO_{\rho_2} \tau_2 \\
      \textsf{ok} \ \rho_1 \cup \rho_2}
      { \centerdot \vdash v \curlyvee w : \IO_{\rho_1 \cup \rho_2} \tau_1 \times \tau_2 } \]
    There is also only one possible reduction that could have
    occurred
    \[ v \curlyvee w \leadsto v \bind \lambda v . (w \bind \lambda w . \lift{v \times w}) \]
    So we need to show ${\centerdot \vdash v \bind \lambda v . (w \bind \lambda w . \lift{v
        \times w}) : \IO_{\rho_1 \cup \rho_2} \tau_1 \times \tau_2}$ --- not exactly the
    prettiest judgement --- which we can construct eventually from a \textsc{Bind}.

    To begin, we will first show that both $v$ and $w$ can be subsumed
    into the larger combined heap, $\rho_1 \cup \rho_2$.
    \begin{align*}
      \centerdot \vdash v : \IO_{\rho_1} \tau_1 && \text{from premises} \\
      \rho_1 \subtyp \rho_1 \cup \rho_2 && \text{by \textsc{UnionL}} \\
      \textsf{ok} \ \rho_1 \cup \rho_2 && \text{from premises} \\
      \centerdot \vdash v : \IO_{\rho_1 \cup \rho_2} \tau_1 && \text{by \textsc{Sub}}
    \end{align*}
    \begin{align*}
      \centerdot \vdash w : \IO_{\rho_2} \tau_2 && \text{from premises} \\
      \centerdot , v : \tau_1 \vdash w : \IO_{\rho_2} \tau_2 && \text{by Lemma~\ref{lem:weaken}} \\
      \rho_2 \subtyp \rho_1 \cup \rho_2 && \text{by \textsc{UnionR}} \\
      \textsf{ok} \ \rho_1 \cup \rho_2 && \text{from premises} \\
      \centerdot , v : \tau_1 \vdash w : \IO_{\rho_1 \cup \rho_2} \tau_2 && \text{by \textsc{Sub}}
    \end{align*}

    Then we show that we can make a lambda, taking a \textit{pure} $\tau_2$, and making
    a $\tau_1\times \tau_2$ inside that new $\IO$ monad.
    \[
      \infer{
        \infer{
          \infer{
            \centerdot, v : \tau_1, w : \tau_2 \vdash v : \tau_1 \\
            \centerdot, v : \tau_1, w : \tau_2 \vdash w : \tau_2}
          {\centerdot, v : \tau_1, w : \tau_2 \vdash v \times w : \tau_1 \times \tau_2}
        }
        {\centerdot, v : \tau_1, w : \tau_2 \vdash \lift{v \times w} : \IO_{\rho_1 \cup \rho_2} \tau_1 \times
          \tau_2}
      }
      {\centerdot, v : \tau_1 \vdash \lambda w . \lift{v \times w} : \tau_2 \rightarrow \IO_{\rho_1 \cup \rho_2} \tau_1 \times \tau_2}
    \]
    We then take this lambda and bind our \textit{monadic} $w$ to it
    \[
      \infer{
        \centerdot , v : \IO_{\rho_1} \tau_1 \vdash w : \IO_{\rho_1 \cup \rho_2} \tau_2 \\
        \centerdot, v : \tau_1 \vdash \lambda w . \lift{v \times w} : \tau_2 \rightarrow \IO_{\rho_1 \cup \rho_2} \tau_1 \times
        \tau_2}
      {\centerdot, v : \tau_1 \vdash w \bind (\lambda w . \lift{v \times w}) : \IO_{\rho_1 \cup
          \rho_2} \tau_1 \times \tau_2}
    \]
    Now we can make another lambda, this time taking in the \textit{pure} $\tau_1$
    \[
      \infer{
        \centerdot, v : \tau_1 \vdash w \bind (\lambda w . \lift{v \times w}) : \IO_{\rho_1 \cup
          \rho_2} \tau_1 \times \tau_2}
      {\centerdot \vdash \lambda v . w \bind (\lambda w . \lift{v \times w}) : \tau_1 \rightarrow \IO_{\rho_1 \cup
          \rho_2} \tau_1 \times \tau_2}
    \]
    And then we finally bind it with our \textit{monadic} $v$
    \[
      \infer{
        \centerdot \vdash v : \IO_{\rho_1 \cup \rho_2} \tau_1 \\
        \centerdot \vdash \lambda v . w \bind \lambda w . \lift{v \times w} : \tau_1 \rightarrow \IO_{\rho_1 \cup
          \rho_2} \tau_1 \times \tau_2}
      {\centerdot \vdash v \bind (\lambda v . w \bind (\lambda w . \lift{v \times w})) : \IO_{\rho_1 \cup
          \rho_2} \tau_1 \times \tau_2}
    \]
    The proof is quite long, but since our typing system is syntax
    directed, it closely matches the expression it reduces to, making
    it easier to construct.
  \item[\rm\textsc{Sub}] Last but not least, we have a subsumption
    typing judgement
    \[
      \infer*[Left=Sub]{\centerdot \vdash e : \IO_\rho \tau \\ \rho \subtyp \rho' \\ \textsf{ok} \ \rho'}
      {\centerdot \vdash e : \IO_{\rho'} \tau}
    \]
    However because we know nothing of the syntax of $e$, $e$ could
    reduce to anything and we are left with some $e'$, such that
    $e \leadsto e'$.  Nevertheless, applying the induction hypothesis with
    $\centerdot \vdash e : \IO_\rho \tau$ and $e \leadsto e'$ gives us
    \[ \centerdot \vdash e' : \IO_\rho \tau \]
    Which we can stick back into \textsc{Sub} to get
    \[ \centerdot \vdash e' : \IO_\rho' \tau \]
  \end{description}
\end{proof}

Together these two properties can ensure that no expression can go
wrong, which within operational semantics means it cannot get
\textit{stuck}. A stuck expression is an expression which cannot be
reduced any further (in its normal form) and is not a
value. The progress theorem has shown that evaluation of any
well-typed expression cannot end up in this state, so it does indeed
evaluate to something in the end. And the preservation theorem
guarantees us that the type of the final value will remain the same.
Therefore we have shown the operational equivalent of the denotational
\[ \Gamma \vdash e : \tau \rightarrow \Gamma \Vdash e : \tau \]

