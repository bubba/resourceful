\chapter{Evaluation and further work}\label{cha:evaluation}

\section{Separation logic}
In Section~\ref{sec:separationologic} we briefly touched separation logic,
but now that we have defined our system we can look at some parallels
between them. Take the frame rule again, which allows additional
predicates to be inferred in a specification, under the condition that
the code does not use any of the variables in the predicate.
\[
  \infer{{\color{gray} \{p\}} \ \emph{code} \ {\color{gray} \{q\}}}
  {{\color{gray} \{p * r\}} \ \emph{code} \ {\color{gray} \{ q * r \}}} \
  \text{\parbox{2in}{where no variable
    occurring free in r is modified by \emph{code}}}
\]
Our well-formed heap judgement has a rule that allows heaps to be
merged, under the condition that they do not overlap:
\[
  \infer{\textsf{ok} \ \rho \\ \textsf{ok} \ \rho' \\ \rho\cap\rho'=\emptyset}
  {\textsf{ok} \ \rho\cup\rho'}
\]
This mirrors the idea in separation logic that we only need to worry
about the variables relevant to our code, or in our terminology, the
resources relevant to our type. So our subsumption rule, \textsc{Sub}, that lets
heaps get promoted to a larger heap, ends up being our version of the
frame rule. And the concurrency rule from separation logic
\[
  \infer{ {\color{gray} \{p_1\}} \ \emph{code}_1 \ {\color{gray} \{q_1\}}
    \\
    {\color{gray} \{p_2\}} \ \emph{code}_2 \ {\color{gray} \{q_2\}}}
  { {\color{gray} \{p_1 * p_2\}} \ \emph{code}_1 \ || \ \emph{code}_2 \
    {\color{gray} \{q_1 * q_2\}}}
\]
Ends up becoming our concurrency typing rule, \textsc{conc}. The
preconditions and postconditions are the heaps in the $\IO$ type, and the
separating conjunction $*$ is our union $\cup$.
\[
  \infer{
    \Gamma \vdash e_1 : \IO_{\rho_1} \tau_1 \\
    \Gamma \vdash e_2 : \IO_{\rho_2} \tau_2 \\
    \textsf{ok} \ \rho_1 \cup \rho_2}
  {\Gamma \vdash e_1 \curlyvee e_2 : \IO_{\rho_1 \cup \rho_2} \ \tau_1 \times \tau_2}
\]

\section{Well formed heaps}
We have proved the system defined in Chapter~\ref{chapter:system} is
sound, and moreover we can show that every concurrent expression has a
well formed heap --- that is a resource is not used more than once in the
heap, and thus not accessed concurrently.

\begin{theorem}[Concurrent heap is well formed]\label{theorem:conc}
  If $\Gamma \vdash e_1 \curlyvee e_2 : \IO_\rho \tau$, then $\textsf{ok} \ \rho$
\end{theorem}
\begin{proof}
  By induction on the possible proofs for $\Gamma \vdash e_1 \curlyvee e_2 : \IO_\rho \tau$.
  \begin{description}
  \item[\rm\textsc{Conc}]
    We need to show $\textsf{ok} \ \rho_1 \cup \rho_2$, and from the premises we have $\textsf{ok} \ \rho_1 \cup \rho_2$.
  \item[\rm\textsc{Sub}]
    We need to show $\textsf{ok} \ \rho'$ and from the premises, we also have $\textsf{ok} \ \rho'$. 
  \end{description}
\end{proof}
As you can see, this just follows from the definition of the
concurrency and subsumption rules.
What we would really like to prove is that \emph{all} monadic
expressions have well formed heaps.
\newtheorem{conjecture}{Conjecture}
\begin{conjecture}\label{conjecture:strongconc}
  If $\centerdot \vdash e : \IO_\rho \tau$, then $\textsf{ok} \ \rho$
\end{conjecture}
This is a stronger version of Theorem~\ref{theorem:conc}. However this
is not made easy in the system as it stands, for one simple yet
annoying reason: Types are not necessarily well formed, and
\textsc{Abs} allows any type to be introduced. This can be easily
shown with the identity function.

\[
  \inferrule*[Right=Abs]{
  \inferrule*[Right=Var]{x : \IO_{\textsf{File} \cup \textsf{File}} \tau  \in
    \centerdot , x : \IO_{\textsf{File} \cup \textsf{File}} \tau \\  \IO_{\textsf{File} \cup \textsf{File}} \tau >
    \IO_{\textsf{File} \cup \textsf{File}} \tau }{\centerdot , x : \IO_{\textsf{File} \cup
      \textsf{File}} \tau \vdash x : \IO_{\textsf{File} \cup \textsf{File}} \tau}
}
{\centerdot \vdash \lambda x . x : \IO_{\textsf{File} \cup \textsf{File}} \tau \rightarrow \IO_{\textsf{File} \cup \textsf{File}} \tau}
\]
\textsc{Abs} acts as a mechanism to generate types with malformed heaps, such as
an $\IO$ monad that contains two \textsf{File}s in its heap.  In
reality this is not an issue, as there is no way to construct a value
to pass into this lambda. Because of this I believe that Conjecture~\ref{conjecture:strongconc} is still
provable, but only when the context only contains well formed type
schemes, and hence why it only applies for the empty context.

We can extend this to include a relation for well formed contexts and
well formed types, and use this in our definition. 

\begin{mathpar}
  \boxed{\textsf{ok} \ \Gamma} \\
  \infer{ }{\textsf{ok} \ \centerdot} \and \infer{\textsf{ok} \ \Gamma \\ \textsf{ok}
    \ \sigma}{\textsf{ok} \ \Gamma , x : \sigma } \\
  \boxed{\textsf{ok} \ \sigma} \\
  \infer{\textsf{ok} \ \tau}{\textsf{ok} \ \forall \alpha_1 , \ldots , \alpha_n \cdot \tau} \\
  \boxed{\textsf{ok} \ \tau} \\
  \infer{ }{\textsf{ok} \ \square} \and
  \infer{ }{\textsf{ok} \ \alpha} \and
  \infer{\textsf{ok} \ \tau \\ \textsf{ok} \ \tau'}{\textsf{ok} \ \tau \rightarrow \tau'}
  \and
  \infer{\textsf{ok} \ \tau \\ \textsf{ok} \ \tau'}{\textsf{ok} \ \tau \times \tau'}
  \and
  \infer{\textsf{ok} \ \tau \\ \textsf{ok} \ \rho}{\textsf{ok} \ \IO_\rho \tau}
\end{mathpar}

\begin{conjecture}
  If $\textsf{ok} \ \Gamma$ and $\Gamma \vdash e : \IO_\rho \tau$, then $\textsf{ok} \ \rho$
\end{conjecture}
So far two lemmas have been proven to aid in the proof of the above
conjecture.
\begin{lemma}
  If $\textsf{ok} \ \tau$ then for any substitution $s$, $\textsf{ok} \ \tau[s]$
\end{lemma}
\begin{lemma}
  If $\textsf{ok} \ \sigma$ and $\sigma > \tau$, then $\textsf{ok} \ \tau$
\end{lemma}
This idea of well formed types adds quite a bit
of extra overhead to the system, so it is left as further work.

\section{Let polymorphism}
All this theory was motivated by a very practical cause: to provide
some simple concurrency guarantees at the type level in a programming
language. Thus the intention is that some of this may eventually make
its way into a type system of an existing or novel language.

So instead of starting with the simply typed lambda calculus, the
system was based off of the Hindley-Damas-Milner system with its
polymorphic type discipline. It cannot be understated the amount of
extra complexity and work this introduced into the proofs for
soundness, but polymorphism is an essential feature in today's
modern functional programming languages. The let polymorphism does not
interact much with the monadic and resourceful parts of the type
system, but it is desirable to show that the two are compatible with
each other regardless.

\section{Almost syntax directed}\label{sec:almost-synt-direct}
As mentioned earlier, the system was based off a syntax directed
treatment of Hindley-Damas-Milner. That meant that there were only
four rules instead of the usual six, where instantiation and
generalisation are rolled into \textsc{Var} and \textsc{Let}
respectively. The main benefit of this was that it meant there was
exactly one typing judgement for each form of syntax, so constructing
proofs for a program was a breeze --- you just follow the corresponding rules
for each term. For example, in the expression $\letin{z = \lambda x . x}{z \
  z}$, a let consisting of an abstraction and an application, the proof begins with a
\textsc{Let}, then the premises \textsc{Abs} and \textsc{App} as shown
in figure~\ref{fig:syntaxdirected}.

\begin{figure}
  \centering
  \begin{mathpar}
    \infer*[Right=Let]{
      \infer*[Right=Abs]{
        \infer*[Right=Var]{x : \tau \in \Gamma \\\\ \tau > \tau}{\Gamma , x : \tau \vdash x : \tau}
      }{\Gamma \vdash \lambda x . x : \tau \rightarrow \tau} \\
      \infer*[Right=App]{
        \infer*[Right=Var]{z : \tau \rightarrow \tau \in \Gamma \\\\ \tau \rightarrow \tau > \tau \rightarrow \tau}{\Gamma , z : \tau \rightarrow \tau \vdash z : \tau \rightarrow \tau} \\\\
        \infer*[Right=Var]{z : \tau \rightarrow \tau \in \Gamma \\\\ \tau \rightarrow \tau > \tau \rightarrow \tau}{\Gamma , z : \tau \rightarrow \tau
          \vdash z : \tau \rightarrow \tau}
      }{\Gamma , z : \tau \vdash z \ z : \tau \rightarrow \tau}
    }
    {\Gamma \vdash \letin{z = \lambda x . x}{z \ z} : \tau \rightarrow \tau}
  \end{mathpar}
  \tikz \graph[tree layout] {
    let/"$\letin{z = \lambda x . x}{z \ z}$";
    abs/"$\lambda x . x$";
    app/"$z \ z$";
    var0/"$x$"; var1/"$z$"; var2/"$z$";
    let -> {abs, app};
    abs -> var0;
    app -> {var1, var2};
  };
  \qquad
  \tikz \graph[tree layout] {
    let/"\textsc{let}";
    abs/"\textsc{abs}";
    app/"\textsc{app}";
    var0/"\textsc{var}"; var1/"\textsc{var}"; var2/"\textsc{var}";
    let -> {abs, app};
    abs -> var0;
    app -> {var1, var2};
  };
  \caption{How syntax directed typing rules mean that the proof tree
    is isomorphic to the syntax tree.}\label{fig:syntaxdirected}
\end{figure}

In our system however, the subsumption rule \textsc{sub} prevents
this. For every typing judgement of the form $\Gamma \vdash e : \IO_\rho \tau$, there
are two possible proofs that can be constructed for it: the proof
corresponding to the syntax of $e$, and \textsc{sub}. Furthermore,
because the subheap relation is reflexive, its possible to have an
infinite proof tree with repeated applications of \textsc{sub} as
shown in figure~\ref{fig:infinitesub}. When
working with proofs this did not turn out to be too big of an
issue, but it is undoubtedly a little bit unsatisfying to lose such a
nice property of the system.

\begin{figure}
  \centering
  \begin{mathpar}
    \mprset {sep=1em}
    \infer*[Left=Sub]{
      \infer*[Left=Sub]{
        \infer*[Left=Sub]{
          \vdots \\
          \textsf{File} \subtyp \textsf{File} \\ \textsf{ok} \ \textsf{File}
        }{\Gamma \vdash \use{\textsf{File}}{\square} : \IO_{\textsf{File}}\square} \\
        \textsf{File} \subtyp \textsf{File} \\ \textsf{ok} \ \textsf{File}
      }{\Gamma \vdash \use{\textsf{File}}{\square} : \IO_{\textsf{File}}\square} \\
      \textsf{File} \subtyp \textsf{File} \\ \textsf{ok} \ \textsf{File}
    }{\Gamma \vdash \use{\textsf{File}}{\square} : \IO_{\textsf{File}} \square}
  \end{mathpar}
  \tikz \graph[tree layout] {
    "$\use{\textsf{File}}{\square}$" -> "$\square$";
  };
  \qquad
  \tikz \graph[tree layout] {
    sub/"\textsc{sub}" ->[loop above] sub;
  };
  \caption{How an infinite chain of \textsc{sub} can be produced,
    leading nowhere.}\label{fig:infinitesub}

\end{figure}


\section{Modelling state within the
  monad}\label{section:modellingstate}
The modelling of the IO monad is extremely simplified, and does
nothing more than sequence computation. To illustrate this point,
the reduction rule for concurrency is completely sequential.
\[ \infer{ }{v \curlyvee w \leadsto v \bind \lambda v . (w \bind \lambda w . \lift{v \times w})} \] In
the real world, this would be pointless. We want to be able to compute
these expressions concurrently, so rewriting everything in terms of
$\bind$ won't cut it. By modelling the state of the world, like what
actually happens in the \mintinline{haskell}{IO} monad of Haskell, we
can perform more advanced reasoning about things such as concurrency.
One such possible method would be to create a new rule for reduction
of monadic computations, that passes about state. Then the concurrency
rule could be written something like this:
\begin{mathpar}
  \boxed{\langle e, s \rangle \leadsto \langle e', s' \rangle} \and
  \infer{\langle e_1, s \rangle \leadsto \langle e_1', s_1' \rangle \\ \langle e_2, s \rangle \leadsto \langle e_2', s_2'
    \rangle}
  {\langle e_1 \curlyvee e_2, s \rangle \leadsto \langle e_1' \times e_2' , s_1' \cup s_2' \rangle}
\end{mathpar}
We could then reason further about how the two states $s_1' \cup s_2'$
are merged --- something that separation logic could be used for. 

\section{Extending the inference algorithm}
One of the main contributions of the Hindley-Damas-Milner system was
the inclusion of a type inference algorithm,
Algorithm~W~\cite{milner1978}. A type system on its own only lets us
ascertain that a program is well-typed, given that we supply it an
expression and a type. But the design of Hindley-Damas-milner made it
possible for the type to be inferred algorithmically, from the program
alone. Algorithm W also always infers the \emph{principal type}: the
most general, polymorphic type an expression could have.  Algorithm~W
freed ML programmers from having to explicitly write type annotations,
and is one of its most iconic features. Naturally, we should explore
extending Algorithm~W to handle our new resourceful types.

\section{Heap polymorphism}
It would be convenient if we were able to have expressions like the
following well-typed:
\begin{align*}
\Gamma &= \centerdot , f : \square \rightarrow \IO_{\textsf{File}} \square, g : \square \rightarrow \IO_{\textsf{Net}} \square \\
\Gamma &\vdash \letin{x = \llbracket \square \rrbracket}{(x \bind f) \curlyvee (x \bind g)} : \IO_{\textsf{File} \cup
  \textsf{Net}} \square \times \square
\end{align*}
This is not possible in the current type system: $x$ needs to be both
$\IO_{\textsf{File}}$ and $\IO_{\textsf{Net}}$ simultaneously! This is
very much the same question that Hindley, Damas and Milner set out to
solve, except instead of polymorphic \textit{types} we want to have
polymorphic \textit{heaps}.
The basic idea for this would involve extending the definition of a
heap to allow for variable lookup, $\textbf{h}$:
\begin{grammar}
  <heap $\rho$> ::= $r$ | $\sigma \cup \sigma'$ | \textsf{World} | $\mathbf{h}$
\end{grammar}
And then redefining substitutions to be pairs of a map from
type variables to types, and a map from heap variables to heaps.
\[ S : ( \alpha \mapsto \tau \times h \mapsto \rho ) \]
Then in the definition of substitution, whenever a mapping from a heap
variable to heap is encountered we would apply the substitution.
\begin{align*}
  (\IO_{\rho'} \tau)[h/\rho] &= \IO_{\rho'[h/\rho]} \tau \\
  r[h/\rho] &= r \\
  (\rho_1 \cup \rho_2)[h/\rho] &= \rho_1[h/\rho] \cup \rho_2[h/\rho] \\
  \textsf{World}[h/\rho] &= \textsf{World} \\
  h'[h/\rho] &=
            \begin{cases}
              \rho & \mathsf{if} h' = h \\
              h' & \mathsf{otherwise}
            \end{cases}
\end{align*}

\section{Dependently typed resources}
So far our resources have just been simple static placeholders that
represented system resources, for example the filesystem and the
network. This is just for the sake of argument: resources can be
as general or as specific as is needed for the programmer's use
case.

Suppose a programmer wanted to perform multiple concurrent
operations on various files. A resource representing the entire
filesystem would be too coarse-grained for this purpose. Instead they
might want to have a separate resource for each file.
\setlength{\grammarindent}{2em}
\begin{grammar} \centering
  <resource $r$> ::= \textsf{foo.txt} | \textsf{bar.txt} | \textsf{baz.txt} \ldots
\end{grammar}
But this is very static. If the programmer writes some code that
operates on a new file, then the new file would need to be appended to
the list of these predefined resources. And what if they don't know
what files they will be touching at typecheck time? Instead, it would
be much more natural if the programmer could write programs like
\begin{align*}
  \textsf{readFile} \ \textsf{``foo.txt''} &: \IO_{\textsf{foo.txt}} \textsf{String} \\
  \textsf{writeFile} \ \textsf{``bar.txt''} &: \textsf{String} \rightarrow
  \IO_{\textsf{bar.txt}} \square
\end{align*}
and have the file automatically \emph{lifted} from the expression and
into the heap of the type. This is a job for \textbf{dependent
  types}: having the type depend on the term. However in our system, our resources and types are not unified. In a
dependently typed lambda calculus, the $\Pi$ rule substitutes values into
types like so\footnote{$\Gamma \vdash \tau : \star$ is a judgement saying that $\tau$ is a
  type in some universe.}
\begin{mathpar}
  \infer{\Gamma \vdash \Pi (x : \tau') . \tau : \star \\ \Gamma , x : \tau' \vdash e : \tau}
  {\Gamma \vdash \lambda x . e : \Pi (x : \tau') . \tau} \\
  \infer{\Gamma \vdash e : \Pi (x : \tau') . \tau \\ e' : \tau'}
  {\Gamma \vdash e \ e' : \tau[e'/\tau']}
\end{mathpar}
We would need to combine the syntaxes for resources and types together
for this rule, or flesh out types to include type constructors
through which resources and heaps could be embedded in.
Alternatively, we could be lazy and avoid this by making it dependent
only in the heap. We could introduce a type of lambda for
$\IO$ monads that tags it with a placeholder resource, which gets
substituted when an argument is applied.
\begin{mathpar}
  \infer{\Gamma, x : \tau' \vdash e : \tau }
  {\Gamma \vdash (\lambda_\IO x . e) : \tau' \rightarrow_\IO \tau} \\
  \infer{\Gamma \vdash e : \tau' \rightarrow_\IO \tau \\ \textsf{Value} \ e' \\ \Gamma \vdash e' : \tau'}
  {\Gamma \vdash e \ e' : \IO_{e'} \tau}
\end{mathpar}
It would be wise to restrict this to values, so we aren't going about
tagging resources with half-evaluated computations. We would also need
a notion of equality for values so that we can safely tell what values
are disjoint within a heap. This will pose some interesting challenges
in practice, like knowing statically what variable expressions might
represent the same resource. Does the typechecker here know that $x=y$?
\begin{flalign*}
  &x \gets \textsf{readLine} \\
  &\textsf{readFile} \ x \\
  &\letin{y = x}{\textsf{writeFile} \ y \ \textsf{``hello''}}
\end{flalign*}

\section{Casting heaps}
 We have only been passing about the
primitive unit type, but realistically we are going to want to have
functions that actually have functionality, like the aforementioned
\[\textsf{readFile} : \textsf{String} \rightarrow \IO_\rho \textsf{String}\]
A function like this is not going to be built-in, instead it will
probably be part of a standard library. So how will it be
implemented? The easiest solution would be to
wrap around an existing function that reads files in a plain $\IO$
monad. Remember that plain $\IO$ is equivalent to
$\IO_{\textsf{World}}$:
\[\textsf{readFile'} : \textsf{String} \rightarrow \IO_{\textsf{World}}
  \textsf{String} \]
How do we bring the $\IO$ monad into a $\textsf{File}$ heap?
If it were a pure computation, then we could have just used the use operator:
\[\lambda s \rightarrow \use{\textsf{File}}{\textsf{readFile'} \ s }\]
But it's a monadic computation, so we would end up with a doubly
nested monad like
${\IO_{\textsf{File}} (\IO_{\textsf{World}} \textsf{String})}$. Can we
subsume it? No! Because \textsf{World} is at the top of the
sub-heap chain. It already uses all possible resources, and we can't
claim that it uses less than what it actually does! The type is overly
cautious in this case.

In an ideal world, standard library functions would built up from a
handful of built-ins for extremely low level primitives, that keep
track of things like file descriptors. Then when they are put
together, we could subsume them to keep track of higher-level
resources. For example, after opening several file descriptors, we
could say we are using them to access a database. But practically, we
are going to have to port functions that use the full
$\IO_{\textsf{World}}$ monad to, a monad that uses only the resources
that we \emph{know} the function is accessing.

Haskell's \texttt{base} library contains the
\mintinline{haskell}{unsafePerformIO} function, which has the
blasphemous type signature \mintinline{haskell}{IO a -> a}. But it
provides an escape mechanism for library authors to tell the type
checker that something really doesn't have any side effects, and is
safe to use as such. If we are to allow library authors to annotate
their heaps correctly, one such solution would be to provide an
unsafe function like this, except instead of discarding the $\IO$
part, it would discard heap annotations.
\[ \textsf{unsafeCastHeap} : \IO_\rho \alpha \rightarrow \IO_{\rho'} \alpha \]

There is an
implicit element of trust here that this will be used selectively by
library authors, only when they know that a function accesses a
specific set of resources, and only those resources.

Another more radical approach to this would be to flip \textsf{World}
on its head: Introduce a notion of an ``empty'' heap which contains no
resources, and as such is distinct from all other heaps. Existing code
in a plain $\IO$ monad would have this empty heap by default, and when a
library author wants to tag resources a function might use, they would
subsume it upwards into the heap they want.

%%% Local Variables:
%%% TeX-master: "report"
%%% TeX-engine: luatex
%%% TeX-command-extra-options: "-shell-escape"
%%% End:

% LocalWords:  monadic
